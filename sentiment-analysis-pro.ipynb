{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2157,"sourceType":"datasetVersion","datasetId":18}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing Libraries & Setup","metadata":{}},{"cell_type":"code","source":"# First things first, I'll import all the libraries I need.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport re\nfrom bs4 import BeautifulSoup\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import TextVectorization\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Setting a nice visual style for the plots.\nsns.set_style(\"whitegrid\")\nprint(\"Libraries imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T10:52:25.446886Z","iopub.execute_input":"2025-07-22T10:52:25.447214Z","iopub.status.idle":"2025-07-22T10:52:26.559949Z","shell.execute_reply.started":"2025-07-22T10:52:25.447189Z","shell.execute_reply":"2025-07-22T10:52:26.558956Z"}},"outputs":[{"name":"stdout","text":"Libraries imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Loading the Data","metadata":{}},{"cell_type":"code","source":"# ### 1. Data Loading & Initial Setup ###\n# I'll load the dataset from the default Kaggle directory.\nprint(\"Step 1: Loading Data...\")\nfile_path = '/kaggle/input/amazon-fine-food-reviews/Reviews.csv'\ndf = pd.read_csv(file_path)\n\n# Keeping only the columns I need for this analysis\ndf = df[['ProductId', 'Score', 'Text']]\ndf.dropna(inplace=True)\n\nprint(f\"Dataset loaded successfully. Initial shape: {df.shape}\")\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:09:48.580127Z","iopub.execute_input":"2025-07-21T22:09:48.580411Z","iopub.status.idle":"2025-07-21T22:09:56.461680Z","shell.execute_reply.started":"2025-07-21T22:09:48.580393Z","shell.execute_reply":"2025-07-21T22:09:56.460859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"**Calculating Review Lengths**","metadata":{}},{"cell_type":"code","source":"# For my EDA, I'll start by calculating the length of each review.\nprint(\"Starting EDA...\")\ndf['ReviewLength'] = df['Text'].apply(lambda x: len(x.split()))\n\n# I want to filter out super long reviews, so I'll find the 98th percentile.\nlength_percentile_98 = df['ReviewLength'].quantile(0.98)\nprint(f\"The 98th percentile for review length is: {int(length_percentile_98)} words.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:10:00.932048Z","iopub.execute_input":"2025-07-21T22:10:00.932358Z","iopub.status.idle":"2025-07-21T22:10:03.686829Z","shell.execute_reply.started":"2025-07-21T22:10:00.932338Z","shell.execute_reply":"2025-07-21T22:10:03.685998Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Visualizing the Length distribution**","metadata":{}},{"cell_type":"code","source":"# Now, I'll plot the review lengths to see the distribution.\nplt.figure(figsize=(12, 6))\nsns.histplot(df['ReviewLength'], bins=100, kde=True)\nplt.axvline(x=length_percentile_98, color='red', linestyle='--', linewidth=2, label=f'98th Percentile Cutoff')\nplt.title('Distribution of Review Lengths')\nplt.xlim(0, 1000)\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:10:08.281645Z","iopub.execute_input":"2025-07-21T22:10:08.281993Z","iopub.status.idle":"2025-07-21T22:10:11.197485Z","shell.execute_reply.started":"2025-07-21T22:10:08.281968Z","shell.execute_reply":"2025-07-21T22:10:11.196534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Filtering reviews by length**","metadata":{}},{"cell_type":"code","source":"# Time for preprocessing. First, I'll apply the length filter I just found.\nprint(\"Starting Preprocessing...\")\noriginal_rows = len(df)\ndf = df[df['ReviewLength'] <= length_percentile_98].copy()\nprint(f\"Filtered out long reviews. Kept {len(df)} rows from the original {original_rows}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:10:13.981790Z","iopub.execute_input":"2025-07-21T22:10:13.982125Z","iopub.status.idle":"2025-07-21T22:10:14.069342Z","shell.execute_reply.started":"2025-07-21T22:10:13.982100Z","shell.execute_reply":"2025-07-21T22:10:14.068404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Creating Sentiment Labels**","metadata":{}},{"cell_type":"code","source":"# Next, I'll create the 'Sentiment' column and remove the neutral reviews (Score = 3).\ndf['Sentiment'] = df['Score'].apply(lambda x: 1 if x >= 4 else (0 if x <= 2 else -1))\ndf = df[df['Sentiment'] != -1].copy()\nprint(f\"Shape after removing neutral reviews: {df.shape}\")\ndf[['Score', 'Sentiment']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:10:17.178916Z","iopub.execute_input":"2025-07-21T22:10:17.179258Z","iopub.status.idle":"2025-07-21T22:10:17.446942Z","shell.execute_reply.started":"2025-07-21T22:10:17.179234Z","shell.execute_reply":"2025-07-21T22:10:17.445954Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Defining Cleaning Function & Stopwords**","metadata":{}},{"cell_type":"code","source":"# Here I'll define my custom stopword list and the text cleaning function.\n# Well I searched for the Stopwords and created a list of the probable ones as i didn't had any idea about NLTK\nCUSTOM_STOPWORDS = {\n    'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', 'as', 'at',\n    'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'did', 'do',\n    'does', 'doing', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'has', 'have', 'having',\n    'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'it',\n    'its', 'itself', 'just', 'me', 'more', 'most', 'my', 'myself', 'no', 'nor', 'not', 'now', 'o', 'of', 'on',\n    'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 's', 'same', 'she', 'should',\n    'so', 'some', 'such', 't', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there',\n    'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', 'we', 'were',\n    'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'you', 'your', 'yours',\n    'yourself', 'yourselves', 'br',\n    'amazon', 'product', 'order', 'box', 'bag', 'time', 'food', 'taste', 'flavor', 'coffee', 'tea', 'dog', 'cat'\n}\n\ndef clean_text(text):\n    text = BeautifulSoup(text, \"html.parser\").get_text()\n    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n    text = text.lower()\n    tokens = [word for word in text.split() if word not in CUSTOM_STOPWORDS]\n    return \" \".join(tokens)\n\nprint(\"Custom stopwords and cleaning function are defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:10:20.048708Z","iopub.execute_input":"2025-07-21T22:10:20.049055Z","iopub.status.idle":"2025-07-21T22:10:20.063377Z","shell.execute_reply.started":"2025-07-21T22:10:20.049031Z","shell.execute_reply":"2025-07-21T22:10:20.062444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Applying the cleaning of the text from the reviews","metadata":{}},{"cell_type":"code","source":"print(\"Cleaning text data\")\ndf['CleanedText'] = df['Text'].apply(clean_text)\nprint(\"Text cleaning complete.\")\ndf[['Text', 'CleanedText']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:10:23.588447Z","iopub.execute_input":"2025-07-21T22:10:23.588746Z","iopub.status.idle":"2025-07-21T22:11:11.951025Z","shell.execute_reply.started":"2025-07-21T22:10:23.588724Z","shell.execute_reply":"2025-07-21T22:11:11.950176Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"print(\"Engineering final features...\")\ndf['ReviewVolume'] = df.groupby('ProductId')['ProductId'].transform('count')\ndf['MeanSentiment'] = df.groupby('ProductId')['Sentiment'].transform('mean')\ndf['InventoryNeed'] = df['ReviewVolume'] * df['MeanSentiment']\n\nprint(\"Feature engineering complete.\")\ndf[['ProductId', 'ReviewVolume', 'MeanSentiment', 'InventoryNeed']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:11:11.952443Z","iopub.execute_input":"2025-07-21T22:11:11.952719Z","iopub.status.idle":"2025-07-21T22:11:12.242449Z","shell.execute_reply.started":"2025-07-21T22:11:11.952699Z","shell.execute_reply":"2025-07-21T22:11:12.241535Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"markdown","source":"**Defining the Features & Targets**","metadata":{}},{"cell_type":"code","source":"# Time to prepare for the model. I'll define my X and y variables.\nprint(\"Preparing data for modeling...\")\nX = df['CleanedText'].values\ny_sentiment = df['Sentiment'].values\ny_inventory = df['InventoryNeed'].values\n\nprint(f\"Features (X) and Targets (y) are defined. Number of samples: {len(X)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:11:12.243360Z","iopub.execute_input":"2025-07-21T22:11:12.243660Z","iopub.status.idle":"2025-07-21T22:11:12.275474Z","shell.execute_reply.started":"2025-07-21T22:11:12.243634Z","shell.execute_reply":"2025-07-21T22:11:12.274479Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Train-test Split**","metadata":{}},{"cell_type":"code","source":"X_train_val, X_test, y_sentiment_train_val, y_sentiment_test, y_inventory_train_val, y_inventory_test = train_test_split(\n    X, y_sentiment, y_inventory,\n    test_size=0.20,\n    random_state=42,\n    stratify=y_sentiment\n)\n\nX_train, X_val, y_sentiment_train, y_sentiment_val, y_inventory_train, y_inventory_val = train_test_split(\n    X_train_val, y_sentiment_train_val, y_inventory_train_val,\n    test_size=0.25,\n    random_state=42,\n    stratify=y_sentiment_train_val\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:38:50.738286Z","iopub.execute_input":"2025-07-21T22:38:50.738613Z","iopub.status.idle":"2025-07-21T22:38:51.261798Z","shell.execute_reply.started":"2025-07-21T22:38:50.738591Z","shell.execute_reply":"2025-07-21T22:38:51.260944Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Scaling the Target Variable**","metadata":{}},{"cell_type":"code","source":"inventory_scaler = MinMaxScaler()\n\ny_inventory_train_scaled = inventory_scaler.fit_transform(y_inventory_train.reshape(-1, 1))\ny_inventory_val_scaled = inventory_scaler.transform(y_inventory_val.reshape(-1, 1))\ny_inventory_test_scaled = inventory_scaler.transform(y_inventory_test.reshape(-1, 1))\n\nprint(\"InventoryNeed target scaled successfully for all three sets.\")\nprint(f\"Shape of scaled training data: {y_inventory_train_scaled.shape}\")\nprint(f\"Shape of scaled validation data: {y_inventory_val_scaled.shape}\")\nprint(f\"Shape of scaled test data: {y_inventory_test_scaled.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:38:53.818693Z","iopub.execute_input":"2025-07-21T22:38:53.819047Z","iopub.status.idle":"2025-07-21T22:38:53.829424Z","shell.execute_reply.started":"2025-07-21T22:38:53.818995Z","shell.execute_reply":"2025-07-21T22:38:53.828450Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Text Vectorization**","metadata":{}},{"cell_type":"code","source":"# Finally, I'll set up the text vectorizer and adapt it to my training data.\nMAX_TOKENS = 20000\nMAX_LEN = 220\n#I chose the max_len to be 220 as we can use the graph that the over 98 percentile of reviews have the above length majorly\nvectorizer = TextVectorization(max_tokens=MAX_TOKENS, output_mode='int', output_sequence_length=MAX_LEN)\n\nprint(\"Adapting the vectorizer to the training text...\")\nvectorizer.adapt(X_train)\nprint(\"Vectorizer is ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:39:05.924732Z","iopub.execute_input":"2025-07-21T22:39:05.925424Z","iopub.status.idle":"2025-07-21T22:39:10.571556Z","shell.execute_reply.started":"2025-07-21T22:39:05.925398Z","shell.execute_reply":"2025-07-21T22:39:10.570655Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Bidirectional, LSTM, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\nprint(\"Building the advanced multitask model...\")\n\n# 1. Shared Input and Embedding Layers\ninput_layer = Input(shape=(1,), dtype=tf.string, name='text_input')\nvec_layer = vectorizer(input_layer)\nembedding_layer = Embedding(input_dim=MAX_TOKENS, output_dim=128, name='embedding')(vec_layer)\n\n# --- Tower 1: Sentiment Analysis (LSTM architecture) ---\n# This branch is dedicated to the sentiment task.\nlstm_for_sentiment = Bidirectional(LSTM(64), name='sentiment_lstm')(embedding_layer)\nsentiment_output = Dense(1, activation='sigmoid', name='sentiment_output')(lstm_for_sentiment)\n\n\n# --- Tower 2: Inventory Regression (Advanced CNN architecture) ---\n# This branch is dedicated to the inventory task.\nconv_for_inventory = Conv1D(filters=128, kernel_size=5, activation='relu', name='inventory_cnn')(embedding_layer)\npool_for_inventory = GlobalMaxPooling1D(name='inventory_pooling')(conv_for_inventory)\ndense_1_inventory = Dense(128, activation='relu', name='inventory_dense_1')(pool_for_inventory)\ndropout_1_inventory = Dropout(0.5, name='inventory_dropout_1')(dense_1_inventory)\ndense_2_inventory = Dense(64, activation='relu', name='inventory_dense_2')(dropout_1_inventory)\ndropout_2_inventory = Dropout(0.5, name='inventory_dropout_2')(dense_2_inventory)\ninventory_output = Dense(1, activation='linear', name='inventory_output')(dropout_2_inventory)\n\n\n# 3. Create and Compile the Final Model\n# The model takes one input and has two separate outputs.\nmodel = Model(\n    inputs=input_layer,\n    outputs=[sentiment_output, inventory_output]\n)\n\n# Compile with two losses and two sets of metrics\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss={\n        'sentiment_output': 'binary_crossentropy',\n        'inventory_output': 'mean_squared_error'\n    },\n    metrics={\n        'sentiment_output': 'accuracy',\n        'inventory_output': 'mae'\n    },\n    loss_weights={'sentiment_output': 1.0, 'inventory_output': 0.5}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T10:51:57.040032Z","iopub.execute_input":"2025-07-22T10:51:57.040285Z","iopub.status.idle":"2025-07-22T10:52:19.964431Z","shell.execute_reply.started":"2025-07-22T10:51:57.040258Z","shell.execute_reply":"2025-07-22T10:52:19.962867Z"}},"outputs":[{"name":"stderr","text":"2025-07-22 10:51:58.865435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753181519.120111      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753181519.194510      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Building the advanced multitask model...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3768980650.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 1. Shared Input and Embedding Layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mvec_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TOKENS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"],"ename":"NameError","evalue":"name 'tf' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T22:40:25.452093Z","iopub.execute_input":"2025-07-21T22:40:25.452396Z","iopub.status.idle":"2025-07-21T22:40:25.479483Z","shell.execute_reply.started":"2025-07-21T22:40:25.452376Z","shell.execute_reply":"2025-07-21T22:40:25.478800Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"# Now training the model is my goal\nprint(\"\\nTraining the new advanced multitask model...\")\n\nhistory = model.fit(\n    X_train,\n    {'sentiment_output': y_sentiment_train, 'inventory_output': y_inventory_train_scaled},\n    # Use the validation set here\n    validation_data=(\n        X_val,\n        {'sentiment_output': y_sentiment_val, 'inventory_output': y_inventory_val_scaled}\n    ),\n    epochs=10,\n    batch_size=64,\n    verbose=1\n)\n\n# --- After training is complete, evaluate on the final test set ---\nprint(\"\\n--- Final Evaluation on the Test Set ---\")\nfinal_scores = model.evaluate(\n    X_test,\n    {'sentiment_output': y_sentiment_test, 'inventory_output': y_inventory_test_scaled},\n    verbose=0\n)\n\n# Keras's model.evaluate returns: [total_loss, sentiment_loss, inventory_loss, sentiment_accuracy, inventory_mae]\nprint(f\"Final Test Accuracy: {final_scores[3]:.4f}\")\nprint(f\"Final Test MAE: {final_scores[4]:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation & Insights","metadata":{}},{"cell_type":"markdown","source":"**Plotting the Training History**","metadata":{}},{"cell_type":"code","source":"# Now to evaluate. I'll start by plotting the training history to see how it went.\nprint(\"Visualizing training history...\")\nhistory_df = pd.DataFrame(history.history)\nfig, axes = plt.subplots(2, 2, figsize=(16, 10))\nfig.suptitle('Model Training History', fontsize=16)\n\naxes[0, 0].plot(history_df['sentiment_output_accuracy'], label='Train Accuracy')\naxes[0, 0].plot(history_df['val_sentiment_output_accuracy'], label='Validation Accuracy')\naxes[0, 0].set_title('Sentiment Classification Accuracy'); axes[0, 0].legend()\n\naxes[0, 1].plot(history_df['sentiment_output_loss'], label='Train Loss')\naxes[0, 1].plot(history_df['val_sentiment_output_loss'], label='Validation Loss')\naxes[0, 1].set_title('Sentiment Classification Loss'); axes[0, 1].legend()\n\naxes[1, 0].plot(history_df['inventory_output_mae'], label='Train MAE')\naxes[1, 0].plot(history_df['val_inventory_output_mae'], label='Validation MAE')\naxes[1, 0].set_title('Inventory Regression MAE'); axes[1, 0].legend()\n\naxes[1, 1].plot(history_df['inventory_output_loss'], label='Train Loss')\naxes[1, 1].plot(history_df['val_inventory_output_loss'], label='Validation Loss')\naxes[1, 1].set_title('Inventory Regression Loss'); axes[1, 1].legend()\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95]);\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:21:30.097781Z","iopub.execute_input":"2025-07-21T21:21:30.098166Z","iopub.status.idle":"2025-07-21T21:21:31.529397Z","shell.execute_reply.started":"2025-07-21T21:21:30.098136Z","shell.execute_reply":"2025-07-21T21:21:31.528436Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Making Predictions**","metadata":{}},{"cell_type":"code","source":"# Let's use the trained model to make predictions on the test set.\nprint(\"Making predictions on the test set...\")\npred_sentiment, pred_inventory_scaled = model.predict(X_test)\n\n# I need to un-scale the inventory predictions to make sense of them.\npred_inventory = inventory_scaler.inverse_transform(pred_inventory_scaled)\n\nresults_df = pd.DataFrame({\n    'ReviewText': X_test,\n    'ActualSentiment': y_sentiment_test,\n    'PredictedSentiment': (pred_sentiment > 0.5).astype(int).flatten(),\n    'ActualInventoryNeed': y_inventory_test.flatten(),\n    'PredictedInventoryNeed': pred_inventory.flatten().round(2)\n})\n\nprint(\"Predictions are ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T20:52:11.998751Z","iopub.execute_input":"2025-07-21T20:52:11.999087Z","iopub.status.idle":"2025-07-21T20:54:09.878415Z","shell.execute_reply.started":"2025-07-21T20:52:11.999064Z","shell.execute_reply":"2025-07-21T20:54:09.877349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Sentiment Performance Insights**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\nprint(\"Generating predictions for the test set...\")\npred_sentiment, _ = model.predict(X_test) # We only need the sentiment output here\n\nsentiment_preds_binary = (pred_sentiment > 0.5).astype(int)\n\nprint(\"\\n--- Sentiment Classification Insights ---\")\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_sentiment_test, sentiment_preds_binary, target_names=['Negative', 'Positive']))\n\nprint(\"\\nConfusion Matrix:\")\ncm = confusion_matrix(y_sentiment_test, sentiment_preds_binary)\nplt.figure(figsize=(7, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Negative', 'Positive'],\n            yticklabels=['Negative', 'Positive'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Sentiment Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:00:30.856830Z","iopub.execute_input":"2025-07-21T21:00:30.857205Z","iopub.status.idle":"2025-07-21T21:02:26.655561Z","shell.execute_reply.started":"2025-07-21T21:00:30.857181Z","shell.execute_reply":"2025-07-21T21:02:26.654664Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inventory Regression Insights**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nprint(\"\\n--- Inventory Regression Insights ---\")\n\n# 1. Calculate the Mean Absolute Error on the test set predictions\n# This compares the true inventory values (y_inventory_test) with the predicted ones.\ntest_mae = mean_absolute_error(y_inventory_test, pred_inventory)\n\nprint(f\"Mean Absolute Error (MAE) on the Test Set: {test_mae:.4f}\")\nprint(\"This means, on average, the model's prediction is off by this many units.\")\n\n\n# 2. Create the scatter plot of actual vs. predicted values\nplt.figure(figsize=(8, 8))\nsns.scatterplot(x=y_inventory_test.flatten(), y=pred_inventory.flatten(), alpha=0.5)\n\n# Add a line for perfect predictions (y=x)\nmax_val = max(y_inventory_test.max(), pred_inventory.max())\nmin_val = min(y_inventory_test.min(), pred_inventory.min())\nplt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction Line')\n\nplt.xlabel('Actual Inventory Need')\nplt.ylabel('Predicted Inventory Need')\nplt.title('Actual vs. Predicted Inventory Need')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:03:39.117573Z","iopub.execute_input":"2025-07-21T21:03:39.117966Z","iopub.status.idle":"2025-07-21T21:03:40.758255Z","shell.execute_reply.started":"2025-07-21T21:03:39.117939Z","shell.execute_reply":"2025-07-21T21:03:40.757286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Finally, I'll look at a few examples to see how the model did.\nprint(\"Sample Predictions from the Model:\")\npd.set_option('display.max_colwidth', 150)\nresults_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T20:54:52.596793Z","iopub.execute_input":"2025-07-21T20:54:52.597167Z","iopub.status.idle":"2025-07-21T20:54:52.610756Z","shell.execute_reply.started":"2025-07-21T20:54:52.597134Z","shell.execute_reply":"2025-07-21T20:54:52.609987Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Trying Bulk Prediction on New Reviews","metadata":{}},{"cell_type":"code","source":"# Create a dummy DataFrame with new, unseen reviews.\nnew_reviews_data = {\n    'product_id': ['B008V1L4C2', 'B001E5E3L0', 'B000G7M4A2'],\n    'review_text': [\n        \"Absolutely fantastic! I'm so happy with this purchase.\",\n        \"It was okay, not great but not terrible either.\",\n        \"A complete waste of money. I regret buying this.\"\n    ]\n}\nnew_df = pd.DataFrame(new_reviews_data)\n\n# 1. Clean the text column.\nnew_df['cleaned_text'] = new_df['review_text'].apply(clean_text)\n\n# 2. Predict on the entire column after converting it to a NumPy array.\npred_sentiment, pred_inventory_scaled = model.predict(new_df['cleaned_text'].values)\n\n# 3. Add predictions to the DataFrame.\nnew_df['predicted_sentiment_score'] = pred_sentiment\nnew_df['predicted_inventory_need'] = inventory_scaler.inverse_transform(pred_inventory_scaled)\n\n# 4. Display the results.\nprint(\"--- Bulk Prediction Results ---\")\nprint(new_df[['product_id', 'review_text', 'predicted_sentiment_score', 'predicted_inventory_need']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T20:56:15.515727Z","iopub.execute_input":"2025-07-21T20:56:15.516090Z","iopub.status.idle":"2025-07-21T20:56:15.652734Z","shell.execute_reply.started":"2025-07-21T20:56:15.516066Z","shell.execute_reply":"2025-07-21T20:56:15.651767Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Final Insights and Model Inference\n\nBased on the evaluation metrics and visualizations, we can draw several key conclusions about the model's performance and its potential business applications.\n\n---\n\n### 1. Sentiment Analysis Performance: Highly Accurate\n\n* **Overall Accuracy:** The model achieved a good accuracy on the test set, demonstrating a strong ability to distinguish between positive and negative reviews.\n\n* **Confusion Matrix Insights:** The confusion matrix reveals that the model is very effective at correctly identifying both **Positive** (True Positives) and **Negative** (True Negatives) reviews. The number of misclassifications (False Positives and False Negatives) is relatively low, indicating a well-balanced classifier.\n\n* **Precision and Recall:** The high **Precision** score shows that when the model predicts a review is positive, it is correct a vast majority of the time. Similarly, a high **Recall** score indicates that the model successfully identifies most of the actual positive reviews in the dataset, missing very few.\n\n---\n\n### 2. Inventory Need Regression Performance: Strong Correlation\n\n* **Actual vs. Predicted Plot:** The scatter plot shows a clear and strong positive correlation between the actual and predicted inventory needs. Most data points are clustered tightly around the \"Perfect Prediction Line,\" which signifies that the model has successfully learned the underlying relationship between a review's sentiment and the resulting product demand.\n\n* **Model Tendencies:** The model appears to be most accurate for products with low-to-medium inventory need scores. For products with extremely high demand, we see slightly more variance, which is expected and could be improved by training on more data from high-volume products.\n\n* **Error Analysis:** The Mean Absolute Error (MAE) on the test set is good. This means that, on average, our model's prediction for the `InventoryNeed` score is off by approximately that many units, which is a very acceptable margin for demand forecasting.\n\n---\n\n### 3. Business Implications & Next Steps\n\n* **Actionable Insights:** This dual-output model is a powerful tool. We can automatically flag products experiencing a surge in negative sentiment to proactively address quality control issues. Simultaneously, the inventory prediction can alert the supply chain team to prepare for shifts in demand based directly on the voice of the customer.\n\n* **Future Improvements:** To enhance the model further, we could experiment with more complex architectures like Transformers (e.g., BERT). Additionally, deploying this model into a real-time dashboard would empower product managers and supply chain analysts to make faster, data-driven decisions.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}